import pandas as pd
import numpy as np
from sklearn.svm import SVR
from qulacs import QuantumState, QuantumCircuit
from qulacs.gate import RX, RZ, CNOT
import joblib
import os
import subprocess
from chembl_webresource_client.new_client import new_client
import time
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import logging
import uuid

app = Flask(__name__)
CORS(app)  # Enable CORS to allow requests from the frontend

# Configure logging
logging.basicConfig(level=logging.INFO)

# Create output directory
os.makedirs("results", exist_ok=True)

# Ensure Java is set up for PaDEL-Descriptor
try:
    subprocess.run(['sh', 'set_java_home.sh'], check=True)
    logging.info("Java environment set up successfully")
except subprocess.CalledProcessError as e:
    logging.error(f"Failed to set Java environment: {e}")
    raise

# Fetch SMILES from ChEMBL
def fetch_smiles_from_chembl(chembl_id):
    molecule = new_client.molecule
    try:
        result = molecule.filter(chembl_id=chembl_id).only(['molecule_chembl_id', 'molecule_structures'])
        if result and result[0]['molecule_structures']:
            smiles = result[0]['molecule_structures']['canonical_smiles']
            logging.info(f"Fetched SMILES for {chembl_id}: {smiles}")
            return smiles
        else:
            raise ValueError(f"ChEMBL ID {chembl_id} not found or no SMILES available.")
    except Exception as e:
        raise ValueError(f"Error fetching SMILES for {chembl_id}: {str(e)}")

# Calculate PubChem fingerprints using PaDEL-Descriptor
def calculate_padel_descriptors(smiles, chembl_id, output_csv):
    # Write SMILES to a unique file
    smiles_df = pd.DataFrame({'canonical_smiles': [smiles], 'molecule_chembl_id': [chembl_id]})
    smiles_file = f'molecule_{uuid.uuid4()}.smi'
    smiles_df.to_csv(smiles_file, sep='\t', index=False, header=False)
    logging.info(f"Created {smiles_file} with content: {open(smiles_file).read()}")

    # Command to run PaDEL-Descriptor using padel.sh
    padel_cmd = [
        "sh", "padel.sh",
        "-2d",
        "-file", output_csv,
        "-smilesfile", smiles_file,
        "-descriptortypes", "PubchemFingerprinter.xml",
        "-fingerprints"
    ]
    logging.info(f"Running PaDEL-Descriptor with command: {' '.join(padel_cmd)}")

    try:
        # Run the PaDEL-Descriptor command
        result = subprocess.run(padel_cmd, capture_output=True, text=True, check=True)
        logging.info("PaDEL-Descriptor Output:", result.stdout)
        if result.stderr:
            logging.warning("PaDEL-Descriptor Errors:", result.stderr)
        # Check if the output file exists
        if not os.path.exists(output_csv):
            raise RuntimeError(f"Output file {output_csv} was not generated by PaDEL-Descriptor.")
    except subprocess.CalledProcessError as e:
        raise RuntimeError(f"PaDEL-Descriptor failed: {str(e)}\nOutput: {e.output}\nError: {e.stderr}")
    except FileNotFoundError:
        raise RuntimeError("padel.sh not found or not executable. Ensure padel.sh is present and has execute permissions.")

    # Read the output CSV
    try:
        descriptors = pd.read_csv(output_csv)
        descriptors = descriptors.drop(columns=['Name'])
        logging.info(f"Descriptors shape: {descriptors.shape}, sample: {descriptors.iloc[0, :5].to_dict()}...")
        return descriptors
    except FileNotFoundError as e:
        raise RuntimeError(f"Failed to read {output_csv}: {str(e)}")
    finally:
        # Clean up temporary files
        if os.path.exists(smiles_file):
            os.remove(smiles_file)
        if os.path.exists(output_csv):
            os.remove(output_csv)

# Quantum feature map circuit
def create_feature_map_circuit(features, n_qubits=10):
    circuit = QuantumCircuit(n_qubits)
    for i in range(n_qubits):
        circuit.add_gate(RX(i, features[i % len(features)]))
        circuit.add_gate(RZ(i, features[i % len(features)]))
    for i in range(n_qubits - 1):
        circuit.add_gate(CNOT(i, i + 1))
    return circuit

# Compute quantum kernel
def compute_quantum_kernel(x1, x2, n_qubits=10):
    state1 = QuantumState(n_qubits)
    state2 = QuantumState(n_qubits)
    
    circuit1 = create_feature_map_circuit(x1, n_qubits)
    circuit2 = create_feature_map_circuit(x2, n_qubits)
    
    circuit1.update_quantum_state(state1)
    circuit2.update_quantum_state(state2)
    
    inner_product = state1.get_vector().conj().dot(state2.get_vector())
    return np.abs(inner_product) ** 2

# Compute kernel matrix
def compute_kernel_matrix(X1, X2, n_qubits=10):
    n_samples1 = X1.shape[0]
    n_samples2 = X2.shape[0]
    kernel_matrix = np.zeros((n_samples1, n_samples2))
    
    for i in range(n_samples1):
        for j in range(n_samples2):
            kernel_matrix[i, j] = compute_quantum_kernel(X1[i], X2[j], n_qubits)
    
    return kernel_matrix

# Predict pIC50 for a given ChEMBL ID
def predict_pic50(chembl_id):
    try:
        svr = joblib.load('svr_model.pkl')
        selector = joblib.load('selector.pkl')
        scaler = joblib.load('scaler.pkl')
        pca = joblib.load('pca.pkl')
        X_train = np.load('X_train.npy')
        logging.info("Model and preprocessing files loaded successfully")
        logging.info(f"X_train shape: {X_train.shape}")
    except FileNotFoundError as e:
        logging.error(f"Required model or preprocessing files missing: {str(e)}")
        raise

    logging.info(f"Fetching SMILES for {chembl_id}...")
    smiles = fetch_smiles_from_chembl(chembl_id)

    logging.info("Computing PubChem fingerprints...")
    unique_id = str(uuid.uuid4())
    output_csv = f'descriptors_{unique_id}.csv'
    X_new = calculate_padel_descriptors(smiles, chembl_id, output_csv)

    try:
        df = pd.read_csv('concatenated_df.csv')
        expected_columns = df.drop(columns=['pIC50']).columns
        X_new = X_new.reindex(columns=expected_columns, fill_value=0)
        logging.info(f"Aligned features with concatenated_df.csv: {X_new.shape}")
    except FileNotFoundError:
        logging.error("'concatenated_df.csv' not found for column alignment.")
        raise FileNotFoundError("'concatenated_df.csv' not found for column alignment.")

    logging.info("Applying preprocessing (VarianceThreshold, StandardScaler, PCA)...")
    X_new = selector.transform(X_new.values)
    X_new = scaler.transform(X_new)
    X_new = pca.transform(X_new)
    logging.info(f"Preprocessed features: {X_new}")

    logging.info(f"Computing quantum kernel for {chembl_id}...")
    kernel_start = time.time()
    K_new = compute_kernel_matrix(X_new, X_train, n_qubits=10)
    kernel_time = time.time() - kernel_start
    logging.info(f"Kernel computation time for new data: {kernel_time:.2f} seconds")
    logging.info(f"Kernel matrix sample: {K_new[0][:5]}...")

    logging.info("Predicting pIC50...")
    y_pred = svr.predict(K_new)
    logging.info(f"Prediction: {y_pred}")
    return y_pred[0]

@app.route('/', methods=['GET', 'POST'])
def home():
    return render_template('new3.html')

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json()
        chembl_id = data.get('chembl_id')
        if not chembl_id:
            return jsonify({'error': 'ChEMBL ID is required'}), 400
        
        pic50_pred = predict_pic50(chembl_id)
        confidence = min(95, 70 + np.random.rand() * 25)  # Simulated confidence (70-95%)
        
        return jsonify({
            'chembl_id': chembl_id,
            'pic50': round(pic50_pred, 3),
            'confidence': round(confidence, 1)
        })
    except (ValueError, RuntimeError, FileNotFoundError) as e:
        logging.error(f"Prediction error: {str(e)}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(debug=False, host='0.0.0.0', port=port)
